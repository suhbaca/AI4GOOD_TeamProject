{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suhbaca/AI4GOOD_TeamProject/blob/sasha/LLM2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTWCJnUlvNug"
      },
      "outputs": [],
      "source": [
        "#access huggingface\n",
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "\n",
        "import transformers torch accelerate\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")"
      ],
      "metadata": {
        "id": "poraIR-XvU6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt engineering\n",
        "\n",
        "instruction= 'The user is trying to find a word that matches the description in the prompt. The answer is 5 possible words that the prompt is trying to describe. The following are examples of Prompt-Answer format.\\n'  # eg Given the context provided, answer the question\n",
        "\n",
        "few_shot = \"Prompt: it’s a type of bird, kind of rare. They’re very colorful, with long tails, and they can mimic sounds. They live in tropical areas\\n Answer:  Hummingbird, Parrot, Finch, Toucan, Macaw\\n Prompt: It’s a type of bird, very colorful, and it can mimic human speech. People sometimes keep them as pets. They live in tropical areas.\\nAnswer: Parrot, Macaw, Cockatoo, Canary, Finch\\nPrompt: I need the...you know...the thing for writing\\nAnswer: Pen, Pencil, Quill, Fountain Pen, Crayon\\nPrompt : I want to go to the...um...place where we get groceries\\n  Answer: Store, Supermarket, Market, Grocery, Shop\\nPrompt : \"\n",
        "\n",
        "system_prompt = 'Now it is your turn to give the answer to the last prompt. Give 30 possible words being described instead of just 5 like in the examples. It is important that you give 30 words. It is very important that you only provide the final output without any additional comments or remarks or notes.'\n",
        "  # You will be given the description of a word ....."
      ],
      "metadata": {
        "id": "wuNxKDLkvYYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if the user is submitting a prompt for the first time, there is no extra extra added prompt\n",
        "#if the user reqyests for the words to be reloaded, in the back end the prompt is asked again and an extra prompt saying to omit the already generated words is used"
      ],
      "metadata": {
        "id": "-mz88qGe1X0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prompt():\n",
        "  #get user input from voice recog system\n",
        "\n",
        "  prompt = \"\"\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "iZgEhCla14HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_template(prompt):\n",
        "\n",
        "\n",
        "  instruction= 'The user is trying to find a word that matches the description in the prompt. The answer is 5 possible words that the prompt is trying to describe. The following are examples of Prompt-Answer format.\\n'  # eg Given the context provided, answer the question\n",
        "\n",
        "  few_shot = \"Prompt: it’s a type of bird, kind of rare. They’re very colorful, with long tails, and they can mimic sounds. They live in tropical areas\\n Answer:  Hummingbird, Parrot, Finch, Toucan, Macaw\\n Prompt: It’s a type of bird, very colorful, and it can mimic human speech. People sometimes keep them as pets. They live in tropical areas.\\nAnswer: Parrot, Macaw, Cockatoo, Canary, Finch\\nPrompt: I need the...you know...the thing for writing\\nAnswer: Pen, Pencil, Quill, Fountain Pen, Crayon\\nPrompt : I want to go to the...um...place where we get groceries\\n  Answer: Store, Supermarket, Market, Grocery, Shop\\nPrompt : \"\n",
        "\n",
        "  system_prompt = 'Now it is your turn to give the answer to the last prompt. Give 30 possible words being described instead of just 5 like in the examples. It is important that you give 30 words. It is very important that you only provide the final output without any additional comments or remarks or notes.'\n",
        "  # You will be given the description of a word .....\n",
        "  chat_prompt= instruction + few_shot + prompt + system_prompt\n",
        "  return chat_prompt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PEu9W5oi3E9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pipeline():\n",
        "  pipeline = transformers.pipeline(\n",
        "  \"text-generation\",\n",
        "\n",
        "  model=model,\n",
        "\n",
        "  tokenizer=tokenizer,\n",
        "\n",
        "  torch_dtype=torch.float16,\n",
        "\n",
        "  device_map=\"auto\",\n",
        "\n",
        "  )\n",
        "  return pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "XlC_lXtN3I7Q",
        "outputId": "075382b2-7f96-4551-df25-a2156987adff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-3-53a2ac4d3340>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-53a2ac4d3340>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def create_pipeline():\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_suggestions(chat_prompt):\n",
        "  sequences = pipeline(\n",
        "  chat_prompt,\n",
        "\n",
        "  do_sample=True,\n",
        "\n",
        "  top_k=20,\n",
        "\n",
        "  num_return_sequences=1,\n",
        "\n",
        "  eos_token_id=tokenizer.eos_token_id,\n",
        "\n",
        "  max_length=800,\n",
        "\n",
        "  temperature= 0.3,\n",
        "\n",
        "  return_full_text= False\n",
        "\n",
        "  )\n",
        "\n"
      ],
      "metadata": {
        "id": "noBFw3Pu86vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f1ekoiLHIoHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chat:\n",
        "\n",
        "  def __init__(self) :\n",
        "    words_generated={}\n",
        "\n",
        "\n",
        "  def create_chat(self):\n",
        "\n"
      ],
      "metadata": {
        "id": "kpGcM7LC5xhM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}