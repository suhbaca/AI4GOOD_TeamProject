{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "158ffc73ba394681bed83918fc492c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c5f2ec493a34efb9cae4f896522fc55",
              "IPY_MODEL_a4df467365ea40039f1e17d1b05f70d2",
              "IPY_MODEL_429e5e1ad35b42fda4c5ac806a63cf9a"
            ],
            "layout": "IPY_MODEL_e365230cf805406aad727710602b0487"
          }
        },
        "7c5f2ec493a34efb9cae4f896522fc55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8487801ffcd47aabe29fc0993b25285",
            "placeholder": "​",
            "style": "IPY_MODEL_4d8db7e923654166a82f83e5412039ef",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "a4df467365ea40039f1e17d1b05f70d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ff1f351fbc94d2f8c20c1ed4d1ef23a",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b910b6d74b47445db20e394eaaa514f9",
            "value": 4
          }
        },
        "429e5e1ad35b42fda4c5ac806a63cf9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8cdd306e85f4d4bb874b592e141c98f",
            "placeholder": "​",
            "style": "IPY_MODEL_560068f21f5c4551a33764d71c21535f",
            "value": " 4/4 [01:05&lt;00:00, 14.16s/it]"
          }
        },
        "e365230cf805406aad727710602b0487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8487801ffcd47aabe29fc0993b25285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d8db7e923654166a82f83e5412039ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ff1f351fbc94d2f8c20c1ed4d1ef23a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b910b6d74b47445db20e394eaaa514f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8cdd306e85f4d4bb874b592e141c98f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "560068f21f5c4551a33764d71c21535f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://www.gradio.app/guides/real-time-speech-recognition\n"
      ],
      "metadata": {
        "id": "RAILb6UdGXZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "###you need to run this first, clear the session and then run everything else in the notebook. if it still gives you an error when you try to create the chat object, just restart the session, DONT RUN THIS CELL and run everything else again\n",
        "\n",
        "!pip install -q accelerate"
      ],
      "metadata": {
        "id": "EgcIywTSLIBV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e579eb2-1a40-4eb3-dfd1-ece634bd7d15"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrrrQixs0OEy",
        "outputId": "650fbdd3-cc59-49f2-96f5-7f1c758405a6",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.37.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.111.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==1.0.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.0.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.10)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.2->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.2->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.0.4)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (2.2.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.22.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## llm imports\n",
        "import transformers\n",
        "!pip install -q  bitsandbytes\n",
        "import torch"
      ],
      "metadata": {
        "id": "eUMzERO1LKVE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#access huggingface\n",
        "!huggingface-cli login --token \"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\""
      ],
      "metadata": {
        "id": "DbB1ABPxX6sm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f32b3c-3aa7-43a3-b33f-f349205fa784"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# audio transcription import\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "sJO1jie20a0W",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accelerate.__version__"
      ],
      "metadata": {
        "id": "9UnQKjr9aYq9",
        "outputId": "c5b388de-4464-485a-8b2e-2d0b8a680fb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.31.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######run\n",
        "\n",
        "class Chat:\n",
        "\n",
        "  def __init__(self) :\n",
        "    # model loading etc\n",
        "    self.model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.pipeline = transformers.pipeline(\n",
        "       \"text-generation\",\n",
        "         model=self.model_id,\n",
        "         model_kwargs={\"torch_dtype\": torch.bfloat16,\"load_in_4bit\": torch.cuda.is_available()},\n",
        "         device_map=\"auto\",\n",
        "     )\n",
        "    self.terminators = [\n",
        "     self.pipeline.tokenizer.eos_token_id,\n",
        "     self.pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "     ]\n",
        "\n",
        "#given a prompt it will add the specific instructions that will give the output in the correct format\n",
        "#the current additions use few-shot prompt\n",
        "  def add_template(self, prompt):\n",
        "\n",
        "    #this is the main instruction of what is being done\n",
        "    instruction= 'You are a reverse dictionary chatbot and the user is going to give you a description of the word they are trying to find. You should give 15 possible words they are tyring to describe. Your output should be in the form of a list in this template : [word1, word 2, ..., wordd 25]. Do not add any further comments or notes. Do not repeat any of the words'\n",
        "\n",
        "    messages = [\n",
        "    {\"role\": \"system\", \"content\": instruction },\n",
        "    {\"role\": \"user\", \"content\":  prompt},\n",
        "    ]\n",
        "    return messages\n",
        "\n",
        "  def clean_generated(self, gen):\n",
        "    #first strip the generated answer from 'Answer:'\n",
        "    y=gen.replace('[', '')\n",
        "    z=y.replace(']', '')\n",
        "    possible_words = z.split(',')\n",
        "    #it is possible the current line is in the format : word1, word2, word3, ...-> split on ,\n",
        "    lst = list(dict.fromkeys(possible_words))\n",
        "    z=[m.lstrip() for m in lst ]\n",
        "\n",
        "    return z\n",
        "\n",
        "#this make will take the refined prompt and pass it to the LLM\n",
        "  def get_suggestions(self,prompt):\n",
        "\n",
        "    messages = self.add_template(prompt)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    outputs = self.pipeline(\n",
        "    messages,\n",
        "    max_new_tokens=256,\n",
        "    eos_token_id=self.terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.4,\n",
        "    top_p=0.9,\n",
        "\n",
        "    )\n",
        "    #lst=self.clean_generated(outputs[0][\"generated_text\"][2]['content']\n",
        "\n",
        "    print (self.clean_generated(outputs[0][\"generated_text\"][2]['content']))\n",
        "    lst = (self.clean_generated(outputs[0][\"generated_text\"][2]['content']))\n",
        "    return (lst)\n",
        "\n"
      ],
      "metadata": {
        "id": "n4OgLR4X7yCO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat=Chat()"
      ],
      "metadata": {
        "id": "XL4Zq6Upz8FC",
        "outputId": "ea25695f-6871-40e3-c5e2-792936812d89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "158ffc73ba394681bed83918fc492c29",
            "7c5f2ec493a34efb9cae4f896522fc55",
            "a4df467365ea40039f1e17d1b05f70d2",
            "429e5e1ad35b42fda4c5ac806a63cf9a",
            "e365230cf805406aad727710602b0487",
            "a8487801ffcd47aabe29fc0993b25285",
            "4d8db7e923654166a82f83e5412039ef",
            "0ff1f351fbc94d2f8c20c1ed4d1ef23a",
            "b910b6d74b47445db20e394eaaa514f9",
            "b8cdd306e85f4d4bb874b592e141c98f",
            "560068f21f5c4551a33764d71c21535f"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "158ffc73ba394681bed83918fc492c29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")"
      ],
      "metadata": {
        "id": "y0pAvy58zkfg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('tot.csv')\n",
        "descriptions= list( df['Descriptions'])"
      ],
      "metadata": {
        "id": "kIGNK0zqNj55"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "wkJomoCXOp0Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n3-6eDxfNjiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def transcribe(audio):\n",
        "    sr, y = audio\n",
        "    y = y.astype(np.float32)\n",
        "    y /= np.max(np.abs(y))\n",
        "\n",
        "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
        "\n",
        "def predict(txt):\n",
        "  possible_words=chat.get_suggestions(txt)\n",
        "  return possible_words\n",
        "\n",
        "def clear_audio():\n",
        "    return None, \"\"\n",
        "\n",
        "def change_tab(id):\n",
        "    return gr.Tabs(selected=id)\n",
        "\n",
        "def get_next_suggestions(state):\n",
        "    current_index, suggestions = state\n",
        "    next_index = current_index + 5\n",
        "    display_suggestions = suggestions[current_index:next_index]\n",
        "    state = (next_index, suggestions)\n",
        "\n",
        "    predictedd_words = \"\"\n",
        "    for word in display_suggestions:\n",
        "      predictedd_words += word + \"\\n\"\n",
        "\n",
        "    return predictedd_words, state\n",
        "\n",
        "\n",
        "theme = gr.themes.Soft(\n",
        "  primary_hue=\"emerald\",\n",
        "  secondary_hue=\"lime\",\n",
        "  text_size=\"lg\",\n",
        "  spacing_size=\"lg\",\n",
        "  radius_size=\"lg\",\n",
        ").set(\n",
        "  background_fill_primary='*neutral_100',\n",
        "  shadow_drop='*shadow_drop_lg',\n",
        ")\n",
        "\n",
        "def update_predictions(txt):\n",
        "                suggestions = predict(txt)\n",
        "                state = (0, suggestions)\n",
        "                return get_next_suggestions(state)\n",
        "\n",
        "def handle_example_prompt():\n",
        "    example_text = random.choice(descriptions)\n",
        "    return example_text\n",
        "\n",
        "def clear_text():\n",
        "    return \"\"\n",
        "\n",
        "def reset_example_state():\n",
        "    return None\n",
        "\n",
        "with gr.Blocks(theme=theme) as demo:\n",
        "\n",
        "  with gr.Tabs() as tabs:\n",
        "    example_state = gr.State(None)\n",
        "\n",
        "    with gr.TabItem(\"Transcription\", id=0):\n",
        "      example_prompt_button = gr.Button(\"Example of prompt\")\n",
        "      audio_input = gr.Audio(type=\"numpy\")\n",
        "      clear_button = gr.Button(\"Clear\")\n",
        "      submit_button = gr.Button(\"Submit\")\n",
        "      text_output = gr.Textbox(label=\"Transcription\", max_lines=6)\n",
        "      generate_button = gr.Button(\"Generate Words\")\n",
        "\n",
        "      predict_words_output = gr.Textbox(label=\"Words Suggestion\", visible=False)\n",
        "\n",
        "      submit_button.click(transcribe, inputs=audio_input, outputs=text_output)\n",
        "\n",
        "      clear_button.click(fn=clear_audio, inputs=None, outputs=[audio_input, text_output])\n",
        "      def handle_example_prompt_and_store():\n",
        "                example_text = random.choice(descriptions)\n",
        "                return example_text, example_text\n",
        "\n",
        "      example_prompt_button.click(handle_example_prompt_and_store, inputs=None, outputs=[text_output, example_state])\n",
        "      generate_button.click(update_predictions, inputs=text_output, outputs=predict_words_output)\n",
        "      generate_button.click(change_tab, gr.Number(1, visible=False), tabs)\n",
        "\n",
        "    with gr.TabItem(\"Prediction\", id=1):\n",
        "      text_output2 = gr.Textbox(label=\"Transcription\", max_lines=6)\n",
        "\n",
        "      predict_words_output = gr.Textbox(label=\"Words Suggestion\", max_lines=6)\n",
        "      next_button = gr.Button(\"Next 5 words\")\n",
        "      restart_button = gr.Button(\"Go to previous page\")\n",
        "\n",
        "      suggestion_state = gr.State([0, []])\n",
        "\n",
        "      example_prompt_button.click(lambda state: state, inputs=example_state, outputs=text_output2)\n",
        "      submit_button.click(fn=transcribe, inputs=audio_input, outputs=text_output2)\n",
        "      generate_button.click(fn=update_predictions, inputs=text_output, outputs=[predict_words_output, suggestion_state])\n",
        "      clear_button.click(fn=clear_audio, inputs=None, outputs=[audio_input, predict_words_output])\n",
        "      clear_button.click(fn=clear_text, inputs=None, outputs=text_output2)\n",
        "      clear_button.click(fn=reset_example_state, inputs=None, outputs=example_state)\n",
        "      next_button.click(fn=get_next_suggestions, inputs=suggestion_state, outputs=[predict_words_output, suggestion_state])\n",
        "      restart_button.click(change_tab, gr.Number(0, visible=False), tabs)\n",
        "\n",
        "\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "pF8WI9TL0bom",
        "outputId": "50cafbab-7895-49a5-af2b-86bfda8d730f",
        "collapsed": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://9694236d1140e7caea.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9694236d1140e7caea.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}